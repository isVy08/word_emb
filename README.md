# Unpack Word Embedding Black Box
This repo tracks my (desperate) self-teaching journey of [word embedding](https://en.wikipedia.org/wiki/Word_embedding) algorithms, from primitive frequency-based models to modern superstars like BERT. 
I examine the mathematical bedrock and implement the algorithms from scratch with Numpy. Each algorithm basically comes with 2 files: implementation code and math notes in folder *mian* (math in a nutshell). I also include papers, blogs and other reference materials in the math notes.        

**Updates**: 
- Continuous Bag of Words

Feedbacks and corrections are always welcome. 
<br>You can leave your message here or DM me via Twitter [@isVy08](https://twitter.com/isVy08) </br>
